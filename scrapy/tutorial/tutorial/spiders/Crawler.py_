from twisted.internet import reactor
from scrapy.crawler import CrawlerProcess
from twisted.internet import task
import sys
sys.path.insert(0, '/Users/labuser/Desktop/tutorial/tutorial/spiders')
import ThreadUrl # StackSpider

hosts = ["https://www.npmjs.com/package/browserify", "http://www.npmjs.com/package/grunt-cli", "http://www.npmjs.com/package/bower",
"http://www.npmjs.com/package/gulp", "http://www.npmjs.com/package/grunt", "http://www.npmjs.com/package/express",
"http://www.npmjs.com/package/npm", "http://www.npmjs.com/package/cordova", "http://www.npmjs.com/package/forever"]


def run_crawl():
    """
    Run a spider within Twisted. Once it completes,
    wait 5 seconds and run another spider.
    """
    runner = CrawlerProcess({
        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',
        'FEED_FORMAT': 'json',
        'FEED_URI': 'result.json'
        })
    for i in range(len(hosts)):
       deferred = runner.crawl(ThreadUrl.ThreadUrl(hosts[i]))


l = task.LoopingCall(run_crawl)
l.start(5)

reactor.run()   # you have to run the reactor yourself


