from scrapy import Spider
from scrapy.selector import Selector
from scrapy.http.request import Request

from scrapy.item import Item, Field
import os


class StackItem(Item):
    combo = Field()

class StackSpider(Spider):
    name = "stack"
    allowed_domains = ["npmjs.com"]
    start_urls = ["https://www.npmjs.com/package/browserify", 
                  "http://www.npmjs.com/package/grunt-cli", 
                  "http://www.npmjs.com/package/bower",
                  "http://www.npmjs.com/package/gulp", 
                  "http://www.npmjs.com/package/grunt", 
                  "http://www.npmjs.com/package/express",
                  "http://www.npmjs.com/package/npm", 
                  "http://www.npmjs.com/package/cordova", 
                  "http://www.npmjs.com/package/forever",
    ]
		
    def parse(self, response):
        siblings = Selector(response).xpath(".//h3[contains(text(),'Dependencies (')]/following-sibling::p")
        for sibling in siblings:
            attributes = sibling.xpath(".//a[contains(@href,'package')]/@href").extract()
            for attribute in attributes:
               item = StackItem()
               item['combo'] = response.url + " " + "https://www.npmjs.com" + attribute + " " + "PARENT_OF"
               f = open('workfile','a+')
               if "https://www.npmjs.com" + attribute not in f.read():
                  f.write("https://www.npmjs.com" + attribute + os.linesep)
                  f.close               
               g = open('blanks.csv','r')
               if item['combo'] not in g.read():
                  yield item
                  yield Request("https://www.npmjs.com" + attribute, callback=self.parse)

